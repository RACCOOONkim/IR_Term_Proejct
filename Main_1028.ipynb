{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n",
            "zsh:1: command not found: apt-get\n",
            "The operation couldn’t be completed. Unable to locate a Java Runtime.\n",
            "Please visit http://www.java.com for information on installing Java.\n",
            "\n",
            "zsh:1: command not found: pip\n",
            "zsh:1: command not found: pip\n",
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1-1. 로마 숫자 변환 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roman_to_integer(roman):\n",
        "    roman_values = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
        "    integer = 0\n",
        "    for i in range(len(roman)):\n",
        "        if i > 0 and roman_values[roman[i]] > roman_values[roman[i - 1]]:\n",
        "            integer += roman_values[roman[i]] - 2 * roman_values[roman[i - 1]]\n",
        "        else:\n",
        "            integer += roman_values[roman[i]]\n",
        "    return integer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return ''\n",
        "    \n",
        "    text = re.sub(r'[^\\w\\s.,?]', '', text.lower())\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 텍스트 추출 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-1. Selenium을 사용한 텍스트 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_from_web():\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
        "    driver.get(url)\n",
        "    soup = bs(driver.page_source, 'html.parser')\n",
        "\n",
        "    contents = soup.find('body').string\n",
        "    driver.quit()\n",
        "    \n",
        "    return contents\n",
        "\n",
        "contents = extract_text_from_web()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-2. 책 챕터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_preprocess_book(text):\n",
        "    chapters = []\n",
        "    chapter_numbers = [3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
        "    \n",
        "    chapter_pattern = r\"Chapter\\s+([IVXLCDM]+)\"\n",
        "    chapter_matches = list(re.finditer(chapter_pattern, text, re.IGNORECASE))\n",
        "    \n",
        "    for i, match in enumerate(chapter_matches):\n",
        "        roman_num = match.group(1).upper()\n",
        "        chapter_num = roman_to_integer(roman_num)\n",
        "        if chapter_num in chapter_numbers:\n",
        "            if i+1 < len(chapter_matches):\n",
        "                chapter_text = text[match.start():chapter_matches[i+1].start()]\n",
        "            else:\n",
        "                chapter_text = text[match.start():]\n",
        "            \n",
        "            chapters.append(preprocess_text(chapter_text))\n",
        "    \n",
        "    return chapters, chapter_numbers\n",
        "\n",
        "chapters, chapter_numbers = load_and_preprocess_book(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 벡터 공간 모델 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4-1. VectorSpaceModel 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VectorSpaceModel:\n",
        "    def __init__(self, preprocessed_chapters, chapter_numbers):\n",
        "        self.preprocessed_chapters = preprocessed_chapters\n",
        "        self.chapter_numbers = chapter_numbers\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.chapter_vectors = self.vectorizer.fit_transform(preprocessed_chapters)\n",
        "    \n",
        "    def load_questions(self, file_path):\n",
        "        qa_data = pd.read_excel(file_path)\n",
        "        self.questions = qa_data['질문'].fillna(\"\").tolist()\n",
        "    \n",
        "    def vectorize_queries(self):\n",
        "        self.query_vectors = self.vectorizer.transform(self.questions)\n",
        "    \n",
        "    def calculate_similarity(self):\n",
        "        self.cosine_sim = cosine_similarity(self.query_vectors, self.chapter_vectors)\n",
        "    \n",
        "    def get_top_n_chapters(self, n=3):\n",
        "        self.top_n_chapters = []\n",
        "        for cos_sim in self.cosine_sim:\n",
        "            top_indices = (-cos_sim).argsort()[:n]\n",
        "            top_chapters = [self.chapter_numbers[i] for i in top_indices]\n",
        "            self.top_n_chapters.append(top_chapters)\n",
        "    \n",
        "    def output_results(self):\n",
        "        top_n_df = pd.DataFrame({\n",
        "            'Question': self.questions,\n",
        "            'Top N Chapters': self.top_n_chapters\n",
        "        })\n",
        "        return top_n_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 메인 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5-1. 메인 함수 정의 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    # 책 챕터 로드 및 전처리\n",
        "    chapters, chapter_numbers = load_and_preprocess_book(contents)\n",
        "    \n",
        "    # 벡터 공간 모델 생성 및 질문 처리\n",
        "    question_file_path = 'Q&A_pride_and_prejudice_training.xlsx'\n",
        "    \n",
        "    vsm = VectorSpaceModel(chapters, chapter_numbers)\n",
        "    vsm.load_questions(question_file_path)\n",
        "    vsm.vectorize_queries()\n",
        "    vsm.calculate_similarity()\n",
        "    vsm.get_top_n_chapters(n=3)\n",
        "    \n",
        "    results = vsm.output_results()\n",
        "    print(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
